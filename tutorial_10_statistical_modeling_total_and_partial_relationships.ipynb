{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "Title: Total and Partial Relationships\n",
      "Date: 2013-10-02 23:43\n",
      "Author: cfarmer\n",
      "Email: carson.farmer@gmail.com\n",
      "Category: Statistical Modeling for Python\n",
      "Tags: Helpful tips, Python, Statistical Modeling, Teaching\n",
      "Slug: statistical-modeling-python-total-partial\n",
      "Latex: yes\n",
      "Status: draft"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Total and Partial Relationships\n",
      "\n",
      "## Adjustment\n",
      "\n",
      "There are two basic approaches to adjusting for covariates. Conceptutally, the simplest one is to hold the covariates constant at some level when collecting data or by extracting a subset of data which holds those covariates constant. The other approach is to include the covariates in your models.\n",
      "\n",
      "For example, suppose you want to study the differences in the wages of male and females. The very simple mode `wage ~ sex` might give some insight, but it attributes to `sex` effects that might actually be due to level of education, age, or the second of the economy in which the person works. Here's the result from the simple model:\n",
      "\n",
      "<span class=\"dataset shadow\"><i class=\"icon-flag\" style=\"font-size: 1.5em;\"></i> `cps.csv`</span>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "import statsmodels.formula.api as sm\n",
      "\n",
      "cps = pd.read_csv(\"http://www.mosaic-web.org/go/datasets/cps.csv\")\n",
      "fit0 = sm.ols(\"wage ~ sex\", df=cps).fit()\n",
      "fit0.summary()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<table class=\"simpletable\">\n",
        "<caption>OLS Regression Results</caption>\n",
        "<tr>\n",
        "  <th>Dep. Variable:</th>          <td>wage</td>       <th>  R-squared:         </th> <td>   0.042</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.040</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   23.43</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>Date:</th>             <td>Wed, 02 Oct 2013</td> <th>  Prob (F-statistic):</th> <td>1.70e-06</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>Time:</th>                 <td>23:55:26</td>     <th>  Log-Likelihood:    </th> <td> -1619.8</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>No. Observations:</th>      <td>   534</td>      <th>  AIC:               </th> <td>   3244.</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>Df Residuals:</th>          <td>   532</td>      <th>  BIC:               </th> <td>   3252.</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   \n",
        "</tr>\n",
        "</table>\n",
        "<table class=\"simpletable\">\n",
        "<tr>\n",
        "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th> <th>[95.0% Conf. Int.]</th> \n",
        "</tr>\n",
        "<tr>\n",
        "  <th>Intercept</th> <td>    7.8789</td> <td>    0.322</td> <td>   24.497</td> <td> 0.000</td> <td>    7.247     8.511</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>sex[T.M]</th>  <td>    2.1161</td> <td>    0.437</td> <td>    4.840</td> <td> 0.000</td> <td>    1.257     2.975</td>\n",
        "</tr>\n",
        "</table>\n",
        "<table class=\"simpletable\">\n",
        "<tr>\n",
        "  <th>Omnibus:</th>       <td>214.494</td> <th>  Durbin-Watson:     </th> <td>   1.800</td> \n",
        "</tr>\n",
        "<tr>\n",
        "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>1045.357</td> \n",
        "</tr>\n",
        "<tr>\n",
        "  <th>Skew:</th>          <td> 1.737</td>  <th>  Prob(JB):          </th> <td>1.01e-227</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>Kurtosis:</th>      <td> 8.909</td>  <th>  Cond. No.          </th> <td>    2.73</td> \n",
        "</tr>\n",
        "</table>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 17,
       "text": [
        "<class 'statsmodels.iolib.summary.Summary'>\n",
        "\"\"\"\n",
        "                            OLS Regression Results                            \n",
        "==============================================================================\n",
        "Dep. Variable:                   wage   R-squared:                       0.042\n",
        "Model:                            OLS   Adj. R-squared:                  0.040\n",
        "Method:                 Least Squares   F-statistic:                     23.43\n",
        "Date:                Wed, 02 Oct 2013   Prob (F-statistic):           1.70e-06\n",
        "Time:                        23:55:26   Log-Likelihood:                -1619.8\n",
        "No. Observations:                 534   AIC:                             3244.\n",
        "Df Residuals:                     532   BIC:                             3252.\n",
        "Df Model:                           1                                         \n",
        "==============================================================================\n",
        "                 coef    std err          t      P>|t|      [95.0% Conf. Int.]\n",
        "------------------------------------------------------------------------------\n",
        "Intercept      7.8789      0.322     24.497      0.000         7.247     8.511\n",
        "sex[T.M]       2.1161      0.437      4.840      0.000         1.257     2.975\n",
        "==============================================================================\n",
        "Omnibus:                      214.494   Durbin-Watson:                   1.800\n",
        "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             1045.357\n",
        "Skew:                           1.737   Prob(JB):                    1.01e-227\n",
        "Kurtosis:                       8.909   Cond. No.                         2.73\n",
        "==============================================================================\n",
        "\"\"\""
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The coefficients indicate that a typical male makes \\$2.12 more per hour than a typical female (notice that $R^2 = 0.0422$ is very small: `sex` explains hardly any of the person-to-person variability in wage).\n",
      "\n",
      "By including the variables `age`, `educ`, and `sector` in the model, you can adjust for these variables:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fit1 = sm.ols(\"wage ~ age + sex + educ + sector\", df=cps).fit()\n",
      "fit1.summary()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<table class=\"simpletable\">\n",
        "<caption>OLS Regression Results</caption>\n",
        "<tr>\n",
        "  <th>Dep. Variable:</th>          <td>wage</td>       <th>  R-squared:         </th> <td>   0.302</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.289</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   22.65</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>Date:</th>             <td>Wed, 02 Oct 2013</td> <th>  Prob (F-statistic):</th> <td>2.41e-35</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>Time:</th>                 <td>23:57:23</td>     <th>  Log-Likelihood:    </th> <td> -1535.2</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>No. Observations:</th>      <td>   534</td>      <th>  AIC:               </th> <td>   3092.</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>Df Residuals:</th>          <td>   523</td>      <th>  BIC:               </th> <td>   3140.</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>Df Model:</th>              <td>    10</td>      <th>                     </th>     <td> </td>   \n",
        "</tr>\n",
        "</table>\n",
        "<table class=\"simpletable\">\n",
        "<tr>\n",
        "          <td></td>             <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th> <th>[95.0% Conf. Int.]</th> \n",
        "</tr>\n",
        "<tr>\n",
        "  <th>Intercept</th>         <td>   -4.6941</td> <td>    1.538</td> <td>   -3.053</td> <td> 0.002</td> <td>   -7.715    -1.673</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>sex[T.M]</th>          <td>    1.9417</td> <td>    0.423</td> <td>    4.592</td> <td> 0.000</td> <td>    1.111     2.772</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>sector[T.const]</th>   <td>    1.4355</td> <td>    1.131</td> <td>    1.269</td> <td> 0.205</td> <td>   -0.787     3.658</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>sector[T.manag]</th>   <td>    3.2711</td> <td>    0.767</td> <td>    4.266</td> <td> 0.000</td> <td>    1.765     4.778</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>sector[T.manuf]</th>   <td>    0.8063</td> <td>    0.731</td> <td>    1.103</td> <td> 0.271</td> <td>   -0.630     2.243</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>sector[T.other]</th>   <td>    0.7584</td> <td>    0.759</td> <td>    0.999</td> <td> 0.318</td> <td>   -0.733     2.250</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>sector[T.prof]</th>    <td>    2.2478</td> <td>    0.670</td> <td>    3.356</td> <td> 0.001</td> <td>    0.932     3.564</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>sector[T.sales]</th>   <td>   -0.7671</td> <td>    0.842</td> <td>   -0.911</td> <td> 0.363</td> <td>   -2.421     0.887</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>sector[T.service]</th> <td>   -0.5687</td> <td>    0.666</td> <td>   -0.854</td> <td> 0.394</td> <td>   -1.877     0.740</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>age</th>               <td>    0.1022</td> <td>    0.017</td> <td>    6.167</td> <td> 0.000</td> <td>    0.070     0.135</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>educ</th>              <td>    0.6156</td> <td>    0.094</td> <td>    6.521</td> <td> 0.000</td> <td>    0.430     0.801</td>\n",
        "</tr>\n",
        "</table>\n",
        "<table class=\"simpletable\">\n",
        "<tr>\n",
        "  <th>Omnibus:</th>       <td>230.507</td> <th>  Durbin-Watson:     </th> <td>   1.836</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>2032.042</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>Skew:</th>          <td> 1.659</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>Kurtosis:</th>      <td>11.962</td>  <th>  Cond. No.          </th> <td>    370.</td>\n",
        "</tr>\n",
        "</table>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 18,
       "text": [
        "<class 'statsmodels.iolib.summary.Summary'>\n",
        "\"\"\"\n",
        "                            OLS Regression Results                            \n",
        "==============================================================================\n",
        "Dep. Variable:                   wage   R-squared:                       0.302\n",
        "Model:                            OLS   Adj. R-squared:                  0.289\n",
        "Method:                 Least Squares   F-statistic:                     22.65\n",
        "Date:                Wed, 02 Oct 2013   Prob (F-statistic):           2.41e-35\n",
        "Time:                        23:57:23   Log-Likelihood:                -1535.2\n",
        "No. Observations:                 534   AIC:                             3092.\n",
        "Df Residuals:                     523   BIC:                             3140.\n",
        "Df Model:                          10                                         \n",
        "=====================================================================================\n",
        "                        coef    std err          t      P>|t|      [95.0% Conf. Int.]\n",
        "-------------------------------------------------------------------------------------\n",
        "Intercept            -4.6941      1.538     -3.053      0.002        -7.715    -1.673\n",
        "sex[T.M]              1.9417      0.423      4.592      0.000         1.111     2.772\n",
        "sector[T.const]       1.4355      1.131      1.269      0.205        -0.787     3.658\n",
        "sector[T.manag]       3.2711      0.767      4.266      0.000         1.765     4.778\n",
        "sector[T.manuf]       0.8063      0.731      1.103      0.271        -0.630     2.243\n",
        "sector[T.other]       0.7584      0.759      0.999      0.318        -0.733     2.250\n",
        "sector[T.prof]        2.2478      0.670      3.356      0.001         0.932     3.564\n",
        "sector[T.sales]      -0.7671      0.842     -0.911      0.363        -2.421     0.887\n",
        "sector[T.service]    -0.5687      0.666     -0.854      0.394        -1.877     0.740\n",
        "age                   0.1022      0.017      6.167      0.000         0.070     0.135\n",
        "educ                  0.6156      0.094      6.521      0.000         0.430     0.801\n",
        "==============================================================================\n",
        "Omnibus:                      230.507   Durbin-Watson:                   1.836\n",
        "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             2032.042\n",
        "Skew:                           1.659   Prob(JB):                         0.00\n",
        "Kurtosis:                      11.962   Cond. No.                         370.\n",
        "==============================================================================\n",
        "\"\"\""
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The adjusted difference between the sexes in \\$1.94 per hour (the $R^2 = 0.30$ from this model is considerably larger than for `mod0`, but still a lot of the person-to-person variation in wages has not been captured).\n",
      "\n",
      "It would be wrong to claim that simply including a covariate in a model guarantees that an appropriate adjustment has been made. The effectiveness of the adjustment depends on whether the model design is appropriate, for instance whether appropriate interaction terms have been included. However, it's certainly the case that if you **don't** include the covariate in the model, you have **not** adjusted for it.\n",
      "\n",
      "The other approach is to subsample the data so that the levels of the covariates are approximately constant. For example, here is a subset that considers workers between the ages of 30 and 35 with between 10 to 12 years of education and working in the sales sector fo the economy:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "small = cps[(cps.age<=35) & (cps.age>=30) & (cps.educ>=10) & (cps.educ<=12) & (cps.sector==\"sales\")]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 21
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The choice of these particular levels of `age`, `educ`, and `sector` is arbitrary, but you need to choose some level if you want to hold the covariates approximately contant.\n",
      "\n",
      "The subset of the data can be used to fit a simple mode:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fit2 = sm.ols(\"wage ~ sex\", df=small).fit()\n",
      "fit2.summary()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<table class=\"simpletable\">\n",
        "<caption>OLS Regression Results</caption>\n",
        "<tr>\n",
        "  <th>Dep. Variable:</th>          <td>wage</td>       <th>  R-squared:         </th> <td>   0.964</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.929</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   27.00</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>Date:</th>             <td>Thu, 03 Oct 2013</td> <th>  Prob (F-statistic):</th>  <td> 0.121</td> \n",
        "</tr>\n",
        "<tr>\n",
        "  <th>Time:</th>                 <td>00:26:40</td>     <th>  Log-Likelihood:    </th> <td> -1.5692</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>No. Observations:</th>      <td>     3</td>      <th>  AIC:               </th> <td>   7.138</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>Df Residuals:</th>          <td>     1</td>      <th>  BIC:               </th> <td>   5.336</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   \n",
        "</tr>\n",
        "</table>\n",
        "<table class=\"simpletable\">\n",
        "<tr>\n",
        "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th> <th>[95.0% Conf. Int.]</th> \n",
        "</tr>\n",
        "<tr>\n",
        "  <th>Intercept</th> <td>    4.5000</td> <td>    0.500</td> <td>    9.000</td> <td> 0.070</td> <td>   -1.853    10.853</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>sex[T.M]</th>  <td>    4.5000</td> <td>    0.866</td> <td>    5.196</td> <td> 0.121</td> <td>   -6.504    15.504</td>\n",
        "</tr>\n",
        "</table>\n",
        "<table class=\"simpletable\">\n",
        "<tr>\n",
        "  <th>Omnibus:</th>       <td>   nan</td> <th>  Durbin-Watson:     </th> <td>   1.000</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>Prob(Omnibus):</th> <td>   nan</td> <th>  Jarque-Bera (JB):  </th> <td>   0.281</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>Skew:</th>          <td> 0.000</td> <th>  Prob(JB):          </th> <td>   0.869</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>Kurtosis:</th>      <td> 1.500</td> <th>  Cond. No.          </th> <td>    2.41</td>\n",
        "</tr>\n",
        "</table>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 22,
       "text": [
        "<class 'statsmodels.iolib.summary.Summary'>\n",
        "\"\"\"\n",
        "                            OLS Regression Results                            \n",
        "==============================================================================\n",
        "Dep. Variable:                   wage   R-squared:                       0.964\n",
        "Model:                            OLS   Adj. R-squared:                  0.929\n",
        "Method:                 Least Squares   F-statistic:                     27.00\n",
        "Date:                Thu, 03 Oct 2013   Prob (F-statistic):              0.121\n",
        "Time:                        00:26:40   Log-Likelihood:                -1.5692\n",
        "No. Observations:                   3   AIC:                             7.138\n",
        "Df Residuals:                       1   BIC:                             5.336\n",
        "Df Model:                           1                                         \n",
        "==============================================================================\n",
        "                 coef    std err          t      P>|t|      [95.0% Conf. Int.]\n",
        "------------------------------------------------------------------------------\n",
        "Intercept      4.5000      0.500      9.000      0.070        -1.853    10.853\n",
        "sex[T.M]       4.5000      0.866      5.196      0.121        -6.504    15.504\n",
        "==============================================================================\n",
        "Omnibus:                          nan   Durbin-Watson:                   1.000\n",
        "Prob(Omnibus):                    nan   Jarque-Bera (JB):                0.281\n",
        "Skew:                           0.000   Prob(JB):                        0.869\n",
        "Kurtosis:                       1.500   Cond. No.                         2.41\n",
        "==============================================================================\n",
        "\"\"\""
       ]
      }
     ],
     "prompt_number": 22
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "At first glance, there might seem to be nothing wrong with this approach and, indeed, for vary large datasets it can be effective. In this case however, there are only 3 cases that satisfy the various criteria: two women and one man."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "small.sex.value_counts()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 23,
       "text": [
        "F    2\n",
        "M    1\n",
        "dtype: int64"
       ]
      }
     ],
     "prompt_number": 23
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "So, the \\$4.50 difference in wages between the sexes depends entirely on the data from a single male!\n",
      "**Note**: The 'Confidence in Models' tutorial (Chapter 12) describes how to assess the precision of model coefficients. This one works out to be $4.50 \\pm 11.00$; not at all precise."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Next time on, Statistical Modeling: A Fresh Approach for Python...\n",
      "\n",
      "* **Modeling Randomness**\n",
      "\n",
      "### Reference\n",
      "\n",
      "As with all 'Statistical Modeling: A Fresh Approach for Python' tutorials, this tutorial is based directly on material from ['Statistical Modeling: A Fresh Approach (2nd Edition)'][book] by [Daniel Kaplan][daniel-kaplan].\n",
      "\n",
      "I have made an effort to keep the text and explanations consistent between the original (R-based) version and the Python tutorials, in order to keep things comparable. With that in mind, any errors, omissions, and/or differences between the two versions are mine, and any questions, comments, and/or concerns should be [directed to me][].\n",
      "\n",
      "[book]: http://www.mosaic-web.org/go/StatisticalModeling/\n",
      "[daniel-kaplan]: http://www.macalester.edu/~kaplan/\n",
      "[directed to me]: mailto:carson.farmer@hunter.cuny.edu"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}